import torch 
from torch.utils.data import Dataset  # ä»torch.utils.dataå¯¼å…¥Datasetç±»
from torch.utils.data import DataLoader  # ä»torch.utils.dataå¯¼å…¥DataLoaderç±»
import gzip  # å¯¼å…¥gzipåº“ï¼Œç”¨äºå¤„ç†gzipå‹ç¼©æ–‡ä»¶
import csv  # å¯¼å…¥csvåº“ï¼Œç”¨äºè¯»å–csvæ–‡ä»¶
import matplotlib.pyplot as plt  # å¯¼å…¥matplotlibåº“ï¼Œç”¨äºç»˜å›¾
import numpy as np 
import time  
import math

'''
# @Collector and Speaker : little snow
# @Owner : è€ƒç ”æ•°å­¦è®¡ç®—æœºä¹‹è·¯ 2024-2025 LLMå¾®è°ƒå®æˆ˜é¡¹ç›®
'''

class NameDataset(Dataset):
    def __init__(self, is_train_set):
        # æ ¹æ®æ˜¯å¦æ˜¯è®­ç»ƒé›†é€‰æ‹©æ–‡ä»¶å
        filename = './names_train.csv.gz' if is_train_set else './names_test.csv.gz'
        with gzip.open(filename, 'rt') as f:    # ä»¥åªè¯»æ¨¡å¼æ‰“å¼€gzipæ–‡ä»¶
            reader = csv.reader(f)  # åˆ›å»ºcsvè¯»å–å™¨
            rows = list(reader)  # è¯»å–æ‰€æœ‰è¡Œ
        self.names = [row[0] for row in rows]  # æå–åå­—
        self.len = len(self.names)  # è®°å½•åå­—çš„æ•°é‡
        self.countries = [row[1] for row in rows]  # æå–å¯¹åº”çš„å›½å®¶

        # è·å–å›½å®¶åˆ—è¡¨å¹¶åˆ›å»ºå›½å®¶å­—å…¸
        self.country_list = list(sorted(set(self.countries)))  # å»é‡å¹¶æ’åºå›½å®¶
        self.country_dict = self.getCountryDict()  # åˆ›å»ºå›½å®¶å­—å…¸
        self.country_num = len(self.country_list)  # è®°å½•å›½å®¶æ•°é‡

    def __getitem__(self, index):  # æ ¹æ®ç´¢å¼•è·å–åå­—å’Œå¯¹åº”å›½å®¶çš„ç´¢å¼•
        return self.names[index], self.country_dict[self.countries[index]]

    def __len__(self):
        return self.len  # è¿”å›æ•°æ®é›†çš„é•¿åº¦

    def getCountryDict(self):
        # åˆ›å»ºå›½å®¶å­—å…¸ï¼Œå°†å›½å®¶åæ˜ å°„åˆ°ç´¢å¼•
        country_dict = dict()
        for idx, country_name in enumerate(self.country_list, 0):
            country_dict[country_name] = idx
        return country_dict

    def idx2country(self, index):
        return self.country_list[index]  # æ ¹æ®ç´¢å¼•è¿”å›å›½å®¶å

    def getCountriesNum(self):
        return self.country_num  # è¿”å›å›½å®¶æ•°é‡


HIDDEN_SIZE = 100  # éšè—å±‚å¤§å°
BATCH_SIZE = 256  # æ‰¹å¤„ç†å¤§å°
N_LAYER = 2  # GRUå±‚æ•°
N_EPOCHS = 25  # è®­ç»ƒçš„epochæ•°é‡
# ASCII å­—ç¬¦é›†åŒ…å«äº† 128 ä¸ªå­—ç¬¦ï¼ˆä» 0 åˆ° 127ï¼‰ï¼ŒåŒ…æ‹¬è‹±æ–‡å­—æ¯ã€æ•°å­—ã€æ ‡ç‚¹ç¬¦å·å’Œä¸€äº›æ§åˆ¶å­—ç¬¦
N_CHARS = 128  # GRUä¸­çš„è¾“å…¥å¤§å°ï¼Œæ§åˆ¶åµŒå…¥å±‚çš„å½¢çŠ¶

# åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†åŠæ•°æ®åŠ è½½å™¨
trainSet = NameDataset(is_train_set=True)  # åˆ›å»ºè®­ç»ƒé›†
trainLoader = DataLoader(trainSet, batch_size=BATCH_SIZE, shuffle=True)  # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨
testSet = NameDataset(is_train_set=False)  # åˆ›å»ºæµ‹è¯•é›†
testLoader = DataLoader(testSet, batch_size=BATCH_SIZE, shuffle=False)  # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨

N_COUNTRY = trainSet.getCountriesNum()  # è·å–å›½å®¶æ•°é‡


class RNNClassifier(torch.nn.Module):
    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):
        super(RNNClassifier, self).__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        self.hidden_size = hidden_size  # éšè—å±‚å¤§å°
        self.n_layers = n_layers  # GRUå±‚æ•°
        self.n_directions = 2 if bidirectional else 1  # ä½¿ç”¨åŒå‘GRU

        # åµŒå…¥å±‚ï¼ˆğ‘ ğ‘’ğ‘ğ¿ğ‘’ğ‘›, ğ‘ğ‘ğ‘¡ğ‘â„ğ‘†ğ‘–ğ‘§ğ‘’ï¼‰ --> (ğ‘ ğ‘’ğ‘ğ¿ğ‘’ğ‘›, ğ‘ğ‘ğ‘¡ğ‘â„ğ‘†ğ‘–ğ‘§ğ‘’, hidden_size)
        self.embedding = torch.nn.Embedding(input_size, hidden_size)  # åµŒå…¥å±‚
        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)  # GRUå±‚
        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)  # å…¨è¿æ¥å±‚

    def _init_hidden(self, batch_size):
        # åˆå§‹åŒ–éšè—çŠ¶æ€
        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size) 
        return hidden

    def forward(self, input, seq_lengths):
        # å‰å‘ä¼ æ’­
        # input shape : B x S -> S x B
        input = input.t()  # è½¬ç½®è¾“å…¥
        batch_size = input.size(1)  # è·å–æ‰¹å¤„ç†å¤§å°
        hidden = self._init_hidden(batch_size)  # åˆå§‹åŒ–éšè—çŠ¶æ€
        embedding = self.embedding(input)  # è·å–åµŒå…¥è¡¨ç¤º

        # pack them up
        gru_input = torch.nn.utils.rnn.pack_padded_sequence(embedding, seq_lengths)  # æ‰“åŒ…åºåˆ—
        output, hidden = self.gru(gru_input, hidden)  # GRUå‰å‘ä¼ æ’­
        if self.n_directions == 2:
            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)  # åŒå‘GRUæ‹¼æ¥éšè—çŠ¶æ€
        else:
            hidden_cat = hidden[-1]  # å•å‘GRUçš„éšè—çŠ¶æ€
        fc_output = self.fc(hidden_cat)  # å…¨è¿æ¥å±‚è¾“å‡º
        return fc_output  # è¿”å›è¾“å‡º
    
# è¿™å››ä¸ªä¼ å‚åˆ†åˆ«å¯¹åº”ç±»çš„åˆå§‹åŒ–ä¸­çš„ input_size, hidden_size, output_size, n_layers
classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER)  # åˆ›å»ºåˆ†ç±»å™¨

criterion = torch.nn.CrossEntropyLoss()  # å®šä¹‰æŸå¤±å‡½æ•°
optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)  # å®šä¹‰ä¼˜åŒ–å™¨


def name2list(name):
    # å°†åå­—è½¬æ¢ä¸ºå­—ç¬¦çš„ASCIIå€¼åˆ—è¡¨
    arr = [ord(c) for c in name]  # è·å–æ¯ä¸ªå­—ç¬¦çš„ASCIIå€¼
    return arr, len(arr)  # è¿”å›ASCIIå€¼åˆ—è¡¨å’Œé•¿åº¦


def make_tensors(names, countries):
    # å°†åå­—å’Œå›½å®¶è½¬æ¢ä¸ºå¼ é‡
    sequences_and_lengths = [name2list(name) for name in names]  # è·å–åå­—çš„ASCIIå€¼å’Œé•¿åº¦
    name_sequences = [s1[0] for s1 in sequences_and_lengths]  # æå–ASCIIå€¼åˆ—è¡¨
    seq_lengths = torch.LongTensor([s1[1] for s1 in sequences_and_lengths])  # æå–é•¿åº¦
    countries = countries.long()  # è½¬æ¢å›½å®¶ä¸ºé•¿æ•´å‹

    # åˆ›å»ºåå­—çš„å¼ é‡ï¼Œå½¢çŠ¶ä¸º BatchSize * seqLen
    # ä»–è¿™é‡Œè¡¥é›¶çš„æ–¹å¼å…ˆå°†æ‰€æœ‰çš„0 Tensorç»™åˆå§‹åŒ–å‡ºæ¥ï¼Œç„¶ååœ¨æ¯è¡Œå‰é¢å¡«å……æ¯ä¸ªåå­—
    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()  # åˆå§‹åŒ–å¼ é‡
    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):
        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)  # å¡«å……åå­—çš„ASCIIå€¼

    # æŒ‰é•¿åº¦æ’åºä»¥ä½¿ç”¨pack_padded_sequence
    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)  # æŒ‰é•¿åº¦é™åºæ’åˆ—
    seq_tensor = seq_tensor[perm_idx]  # æ ¹æ®æ’åºç´¢å¼•é‡æ–°æ’åˆ—åå­—å¼ é‡
    countries = countries[perm_idx]  # æ ¹æ®æ’åºç´¢å¼•é‡æ–°æ’åˆ—å›½å®¶å¼ é‡

    # è¿”å›æ’åºåçš„åå­—å¼ é‡ã€é•¿åº¦å¼ é‡å’Œå›½å®¶å¼ é‡
    return seq_tensor, seq_lengths, countries


def trainModel():
    # è®­ç»ƒæ¨¡å‹
    def time_since(since):
        # è®¡ç®—ç»è¿‡çš„æ—¶é—´
        s = time.time() - since
        m = math.floor(s / 60)  # è®¡ç®—åˆ†é’Ÿ
        s -= m * 60  # è®¡ç®—ç§’
        return '%dm %ds' % (m, s)  # è¿”å›æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²

    total_loss = 0  # åˆå§‹åŒ–æ€»æŸå¤±
    for i, (names, countries) in enumerate(trainLoader, 1):  # éå†è®­ç»ƒæ•°æ®
        inputs, seq_lengths, target = make_tensors(names, countries)  # åˆ¶ä½œå¼ é‡

        output = classifier(inputs, seq_lengths)  # å‰å‘ä¼ æ’­
        loss = criterion(output, target)  # è®¡ç®—æŸå¤±
        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
        loss.backward()  # åå‘ä¼ æ’­
        optimizer.step()  # æ›´æ–°å‚æ•°

        total_loss += loss.item()  # ç´¯åŠ æŸå¤±
        if i % 10 == 0:  # æ¯10ä¸ªbatchæ‰“å°ä¸€æ¬¡ä¿¡æ¯
            print(f'[{time_since(start)}] Epoch {epoch} ', end='')
            print(f'[{i * len(inputs)}/{len(trainSet)}] ', end='')
            print(f'loss={total_loss / (i * len(inputs))}')  # æ‰“å°å½“å‰æŸå¤±
    return total_loss  # è¿”å›æ€»æŸå¤±


def testModel():
    # æµ‹è¯•æ¨¡å‹
    correct = 0  # åˆå§‹åŒ–æ­£ç¡®é¢„æµ‹æ•°é‡
    total = len(testSet)  # æµ‹è¯•é›†æ€»æ ·æœ¬æ•°
    print("evaluating trained model ... ")  # æ‰“å°è¯„ä¼°ä¿¡æ¯
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        for i, (names, countries) in enumerate(testLoader):  # éå†æµ‹è¯•æ•°æ®
            inputs, seq_lengths, target = make_tensors(names, countries)  # åˆ¶ä½œå¼ é‡
            output = classifier(inputs, seq_lengths)  # å‰å‘ä¼ æ’­
            pred = output.max(dim=1, keepdim=True)[1]  # è·å–é¢„æµ‹ç»“æœ
            correct += pred.eq(target.view_as(pred)).sum().item()  # ç»Ÿè®¡æ­£ç¡®é¢„æµ‹æ•°é‡

        percent = '%.2f' % (100 * correct / total)  # è®¡ç®—å‡†ç¡®ç‡
        print(f'Test set: Accuracy {correct}/{total} {percent}%')  # æ‰“å°å‡†ç¡®ç‡

    return correct / total  # è¿”å›å‡†ç¡®ç‡


start = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
print("Training for %d epochs..." % N_EPOCHS)  # æ‰“å°è®­ç»ƒä¿¡æ¯
acc_list = []  # åˆå§‹åŒ–å‡†ç¡®ç‡åˆ—è¡¨
for epoch in range(1, N_EPOCHS + 1):  # éå†æ¯ä¸ªepoch
    trainModel()  # è®­ç»ƒæ¨¡å‹
    acc = testModel()  # æµ‹è¯•æ¨¡å‹
    acc_list.append(acc)  # è®°å½•å‡†ç¡®ç‡


epoch = np.arange(1, len(acc_list) + 1)  # åˆ›å»ºepochæ•°ç»„
acc_list = np.array(acc_list)  # è½¬æ¢ä¸ºnumpyæ•°ç»„
plt.plot(epoch, acc_list)  # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
plt.xlabel('Epoch')  # è®¾ç½®xè½´æ ‡ç­¾
plt.ylabel('Accuracy')  # è®¾ç½®yè½´æ ‡ç­¾
plt.grid()  # æ˜¾ç¤ºç½‘æ ¼
plt.savefig('picture/rnn_classifier_accuracy_plot.png')  # ä¿å­˜å‡†ç¡®ç‡å›¾åƒ
print(f"è®­ç»ƒå®Œæˆï¼Œè®­ç»ƒæŒ‡æ ‡å›¾åƒå·²ä¿å­˜åœ¨ picture/rnn_classifier_accuracy_plot.png")  # æ‰“å°å®Œæˆä¿¡æ¯
plt.show()  # æ˜¾ç¤ºå›¾åƒ
